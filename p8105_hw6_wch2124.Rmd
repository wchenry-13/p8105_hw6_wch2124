---
title: "hw6"
output: html_document
date: '2023-11-28'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Load necessary packages 

```{r}
library(tidyverse)
set.seed(1)
```

## problem 1 (0 points)

```{r}
## no work shown for this problem 
```

## problem 2

run code chunk from the course website: 
```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2022-01-01",
    date_max = "2022-12-31") |>
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) |>
  select(name, id, everything())
```

Use 5000 bootstrap samples and, for each bootstrap sample, produce estimates of these two quantities. Plot the distribution of your estimates, and describe these in words. Using the 5000 bootstrap estimates, identify the 2.5% and 97.5% quantiles to provide a 95% confidence interval for r̂ 2
 and log(β̂ 0∗β̂ 1)

```{r}
boot_straps = 
  weather_df |> 
  modelr::bootstrap(n = 5000)

boot_straps |> pull(strap) |> nth(1)

```

Drawing 5000 samples and establishing the 95% CI:
```{r}
boot_straps = 
  weather_df |> 
  modelr::bootstrap(n = 5000)|> 
  mutate(
    models = map(.x = strap, ~lm(tmax ~ tmin + prcp, data = .x)), 
    results = map(models, broom::tidy)) |> 
  select(-strap, -models) |> 
  unnest(results) |> 
  group_by(term) |> 
  select(.id, term, estimate) |>
  pivot_wider(
    names_from = "term",
    values_from = "estimate"
  ) |> 
  janitor::clean_names() |>
  filter(tmin*prcp > 0) |> 
  mutate(
    log_B = log(tmin*prcp) 
  ) |> 
  summarize(
    LL = quantile(log_B, c(.025), na.rm = TRUE),
    UL = quantile(log_B, c(.975), na.rm = TRUE) 
   )
```

Finding R^2: 
```{r}
boot_straps = 
  weather_df |> 
  modelr::bootstrap(n = 5000) |> 
  mutate(
    models = map(strap, ~lm(tmax ~ tmin + prcp, data = .x)),
    results = map(models, broom::glance)
  ) |> 
  select(-strap, -models) |> 
  unnest(results) |> 
  janitor::clean_names() |> 
  summarize(
    LL = quantile(r_squared, c(.025)),
    UL = quantile(r_squared, c(.975)) 
  )
```

Plots: 

```{r}
## r squared plot 

weather_df |> 
  modelr::bootstrap(n = 5000) |> 
  mutate(
    models = map(strap, ~lm(tmax ~ tmin + prcp, data = .x)),
    results = map(models, broom::glance)
  ) |> 
  select(-strap, -models) |> 
  unnest(results) |> 
  ggplot(aes(x = r.squared)) + geom_density() +
  labs(
    title = "insert title here"
  )

```


```{r}
## log plot 

  weather_df |> 
  modelr::bootstrap(n = 5000)|> 
  mutate(
    models = map(.x = strap, ~lm(tmax ~ tmin + prcp, data = .x)), 
    results = map(models, broom::tidy)) |> 
  select(-strap, -models) |> 
  unnest(results) |> 
  group_by(term) |> 
  select(.id, term, estimate) |>
  pivot_wider(
    names_from = "term",
    values_from = "estimate"
  ) |> 
  janitor::clean_names() |>
  filter(tmin*prcp > 0) |> 
  mutate(
    log_B = log(tmin*prcp) 
  ) |> ggplot(aes(x = log_B)) + geom_density() +
  labs(
    title = "insert title here"
  )

```

Problem 3

Load and clean the data for regression analysis: 
```{r}
birthweight_data = 
  read_csv("birthweight.csv") |>  
  janitor::clean_names() |> 
  mutate(
    babysex = as.factor(babysex),
    frace = as.factor(frace),
    malform = as.factor(malform),
    mrace = as.factor(mrace)
  )
```

Propose a regression model for birthweight: 

```{r}
fit_birthweight = lm(bwt ~ smoken + pnumlbw + momage, data = birthweight_data)
fit_birthweight |>  broom::tidy()
```

show a plot of model residuals against fitted values – use add_predictions and add_residuals in making this plot: 

```{r}
birthweight_data |>  
  modelr::add_residuals(fit_birthweight) |> 
  modelr::add_predictions(fit_birthweight) |>  
  ggplot(aes(x = pred, y = resid)) + 
  geom_point() +
  labs(
    title = "Residuals vs Fitted Values",
    x = "Fitted",
    y = "Residuals"
    ) 
```

Compare your model to two others:

```{r}
fit_birthweight2 = lm(bwt ~ + blength + gaweeks, data = birthweight_data)

fit_birthweight3 = lm(bwt ~ bhead + bhead * blength * babysex, data = birthweight_data) 
```

Make this comparison in terms of the cross-validated prediction error; use crossv_mc and functions in purrr as appropriate: 

```{r}

```

